{
  "title": "LLM Memory Management",
  "cardTitle": "LLM Memory Management",
  "cardDescription": "Strategies for managing context windows in long-running conversations.",
  "modalDescription": "Explore advanced strategies for handling context windows in production LLM applications. This guide covers techniques like summarization, selective memory, conversation compression, and hybrid storage approaches. Learn how to build AI assistants that maintain coherent, long-running conversations without hitting token limits.",
  "tags": ["Sep 15", "AI", "LLMs"],
  "link": "post.html?id=llm-memory"
}
